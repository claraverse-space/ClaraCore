# Use llama.cpp's official CPU-only server image
FROM ghcr.io/ggml-org/llama.cpp:server

# Set working directory
WORKDIR /app

# Copy only the ClaraCore binary
COPY claracore /app/claracore

# Make it executable
RUN chmod +x /app/claracore

# Expose port
EXPOSE 5890

# Set the entrypoint
ENTRYPOINT ["/app/claracore"]
CMD ["-listen", "0.0.0.0:5890"]
